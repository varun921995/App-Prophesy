{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from nltk.corpus import words\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_file = \"Google-Playstore-32K.csv\"\n",
    "data_set = pd.read_csv(path_to_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set['Reviews'].value_counts().nlargest(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meghna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Meghna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#unique words from all application names\n",
    "stopWordsList = stopwords.words(\"english\")\n",
    "uniqueWords = []\n",
    "englishWords = words.words()\n",
    "df = data_set[['App Name','Installs','Category']]\n",
    "\n",
    "# df['Installs'] =  pd.to_numeric(df['Installs'].str.replace('[^\\w\\s]',''))\n",
    "df['Installs'] = pd.to_numeric(df['Installs'].str.replace('[^\\w\\s]',''),errors='ignore')\n",
    "df['App Name'] = (df['App Name'].str.replace('[^\\w\\s]',''))\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for idx in range(df.shape[0]):\n",
    "    try:\n",
    "        if(int(df.loc[idx, 'Installs'])):\n",
    "            text = [word.lower() for word in word_tokenize(df.loc[idx, 'App Name']) if (word not in stopWordsList and word in englishWords and len(word)>2)]\n",
    "            z = [ (a,int(df.loc[idx, 'Installs'])) for a in text ]\n",
    "            df_dict.setdefault(df.loc[idx, 'Category'],[]).extend(list(filter(lambda x: x[0] not in stopWordsList, z)))\n",
    "            uniqueWords.extend(text)\n",
    "    except:\n",
    "        continue\n",
    "uniqueWords = set(uniqueWords)\n",
    "\n",
    "# list_of_word_instl = []\n",
    "# for k,v in dicts.items():\n",
    "#     instl = v.replace(',','')\n",
    "#     instl = instl.replace('+','')\n",
    "#     try:\n",
    "#         if(int(instl)):\n",
    "#             text = re.sub(r'[^\\w\\s]','',k)\n",
    "#             text = ([word.lower() for word in word_tokenize(text) if word not in stopWordsList])\n",
    "#             list_of_word_instl.extend(list(map(lambda x: (x,int(instl)), text)))\n",
    "#             uniqueWords.extend(text)\n",
    "#     except:\n",
    "#         continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_dict['FOOD_AND_DRINK']\n",
    "int(max(df_dict['FOOD_AND_DRINK'],key=itemgetter(1))[1])\n",
    "# df_dict['Installs'].value_counts().nlargest(n=1)\n",
    "# len('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict1={}\n",
    "a={}\n",
    "b={}\n",
    "count=0\n",
    "for k,v in df_dict.items():\n",
    "    a = [(uk,round((sum([vv for kk,vv in v if kk==uk])/len([vv for kk,vv in v if kk==uk]))/int(max(v,key=itemgetter(1))[1]),2)) for uk in uniqueWords if (len(uk)>1) if ( sum([vv for kk,vv in v if kk==uk])!= 0)]\n",
    "    df_dict1[k] = dict(a)\n",
    "    count = count+1\n",
    "#     print(len(a),count)\n",
    "    \n",
    "\n",
    "# print(\"20\" in set(words.words()))\n",
    "\n",
    "#     num = [list(map(lambda y:(y[0],y[1]),list(filter(lambda x: x[0]==word, v)))) for word in uniqueWords]\n",
    "#     if(len(num[0])!=0):\n",
    "#         print(len(num)==0)\n",
    "#         print((functools.reduce(lambda a,b :a[1]+b[1],num))/len(num))\n",
    "#     for j in uniqueWords:\n",
    "#         num = list(map(lambda x: x[1],list(filter(lambda x: x[0]==j, v)))) #[('food',10000),('foods',12000)] #'food':[1,2,4]\n",
    "#         if(len(num)!=0):\n",
    "# #             print(j,np.mean(num))\n",
    "#             b[j]=np.mean(num)\n",
    "#     df_dict[k] = b\n",
    "# #             df_dict[k] = (j,np.mean(num))\n",
    "# reduce(lambda a, b: a + b, lst) / len(lst) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('my' in df_dict.values())\n",
    "#stopwords -> reduces installation\n",
    "#length of app name -> not good\n",
    "#\n",
    "df_dict1={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dict['FOOD_AND_DRINK']\n",
    "with open('dataWithMeaningfulWords.json', 'w') as outfile:\n",
    "    json.dump(df_dict1, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #unique words from all application names\n",
    "#     stopWordsList = stopwords.words(\"english\")\n",
    "#     uniqueWords = []\n",
    "#     df = data_set[['App Name','Installs']]\n",
    "#     df = df.set_index('App Name').T.to_dict('records')\n",
    "#     list_of_word_instl = []\n",
    "#     for k,v in df[0].items():\n",
    "#         instl = v.replace(',','')\n",
    "#         instl = instl.replace('+','')\n",
    "#         try:\n",
    "#             if(int(instl)):\n",
    "#                 text = re.sub(r'[^\\w\\s]','',k)\n",
    "#                 text = ([word.lower() for word in word_tokenize(text) if word not in stopWordsList])\n",
    "#                 list_of_word_instl.extend(list(map(lambda x: (x,int(instl)), text))) #array of tuples with words and installations\n",
    "#                 uniqueWords.extend(text)\n",
    "#         except:\n",
    "#             continue\n",
    "        \n",
    "\n",
    "#     uniqueWords = set(uniqueWords)\n",
    "#     for i in uniqueWords:\n",
    "#         num = list(map(lambda x: x[1],list(filter(lambda x: x[0]==i, list_of_word_instl)))) #[('food',10000),('foods',12000)] #'food':[1,2,4]\n",
    "#         print(i,np.mean(num)) #word wrt to installation mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "# lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "# print(\"caf :\", lemmatizer.lemmatize(\"caf\")) \n",
    "# print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# # a denotes adjective in \"pos\" \n",
    "# print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) \n",
    "\n",
    "# if not wordnet.synsets(\"would\"):\n",
    "#     print(\"here\")\n",
    "#   #Not an English Word\n",
    "# else:\n",
    "#     print(\"there\")\n",
    "#   #English Word\n",
    "\n",
    "# nltk.download('words')\n",
    "# import nltk\n",
    "\n",
    "# from nltk.corpus import words\n",
    "# setofwords = set(words.words())\n",
    "\n",
    "# print(\"20\" in set(words.words()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
